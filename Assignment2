%%writefile app.py

import streamlit as st 
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,plot_confusion_matrix,plot_roc_curve,precision_score,recall_score,precision_recall_curve,roc_auc_score,auc
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
import xgboost as xgb

import warnings
warnings.filterwarnings('ignore')
data=pd.read_csv('https://raw.githubusercontent.com/Diane10/ML/master/Customer-Churn.csv')
print(data.head())
print(data.info())
print(data.describe())



#fetuare extracting
#q1 Using the given dataset extract the relevant features that can define a customer churn. [5]
cols=['gender','Dependents','tenure','PhoneService','InternetService','OnlineSecurity','OnlineBackup','TechSupport','PaymentMethod','TotalCharges','Churn']
newdata=data[cols]
print(newdata.info())

le=LabelEncoder()
newdata['gender']=le.fit_transform(newdata['gender'])
newdata['Dependents']=le.fit_transform(newdata['Dependents'])
newdata['PhoneService']=le.fit_transform(newdata['PhoneService'])
newdata['InternetService']=le.fit_transform(newdata['InternetService'])
newdata['OnlineSecurity']=le.fit_transform(newdata['OnlineSecurity'])
newdata['OnlineBackup']=le.fit_transform(newdata['OnlineBackup'])
newdata['TechSupport']=le.fit_transform(newdata['TechSupport'])
newdata['PaymentMethod']=le.fit_transform(newdata['PaymentMethod'])
newdata['Churn']=le.fit_transform(newdata['Churn'])
newdata['TotalCharges']=newdata['TotalCharges'].fillna(newdata['TotalCharges'].mean)
newdata['TotalCharges'] = pd.to_numeric(newdata['TotalCharges'], errors='coerce')
new=newdata[['gender','OnlineSecurity','TechSupport','PaymentMethod','Churn']]
#X=newdata[['gender','Dependents','tenure','PhoneService','InternetService','OnlineSecurity','OnlineBackup','TechSupport','PaymentMethod']]
X=newdata[['gender','OnlineSecurity','TechSupport','PaymentMethod','Churn']]

y=newdata['Churn']
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=0)

from sklearn.preprocessing import StandardScaler
sl=StandardScaler()
X_trained= sl.fit_transform(X_train)
X_tested= sl.fit_transform(X_test)

class_name=['yes','no']
st.title('Customer churn Prediction')

st.markdown("""
Machine Learning models which predict potential customer to churn
""")
st.sidebar.title('Customer churn Prediction')

st.sidebar.markdown("""
Machine Learning models which predict potential customer to churn
""")


if st.sidebar.checkbox("show raw data",False):
    st.subheader("Customer Churn for classification")
    st.write(data)
if st.sidebar.checkbox("Show Encoded Data"):
    st.write(newdata)
if st.sidebar.checkbox("Show a Statistical Analysis"):
	st.write(newdata.describe())

st.sidebar.subheader('Visualization')
if st.sidebar.checkbox("Pair plot",False):
   import seaborn as sns
   st.subheader('Pairplot Graph')
   sns.pairplot(new, hue="Churn")
   st.pyplot()
if st.sidebar.checkbox("Graph plot",False):
   import seaborn as sns
   st.subheader('Counter plot')
   sns.countplot(y="Churn", data=new)
   st.pyplot()

st.sidebar.subheader('Choose Classifer')
classifier_name = st.sidebar.selectbox(
    'Choose classifier',
    ('KNN', 'SVM', 'Random Forest','Logistic Regression','XGBOOST')
)
if classifier_name == 'SVM':
    st.sidebar.subheader('Model Hyperparmeter')
    c= st.sidebar.number_input("c(Reguralization)",0.01,10.0,step=0.01,key='c')
    kernel= st.sidebar.radio("kernel",("linear","rbf"),key='kernel')
    gamma= st.sidebar.radio("gamma(kernel coefficiency",("scale","auto"),key='gamma')

    metrics= st.sidebar.multiselect("What is the metrics to plot?",('confusion matrix','roc_curve','precision_recall_curve'))

    if st.sidebar.button("classify",key='classify'):
        st.subheader("SVM result")
        svcclassifier= SVC(C=c,kernel=kernel,gamma=gamma)
        svcclassifier.fit(X_trained,y_train)
        y_pred= svcclassifier.predict(X_tested)
        acc= accuracy_score(y_test,y_pred)
        st.write("Accuracy:",acc.round(2))
        st.write("precision_score:",precision_score(y_test,y_pred,labels=class_name).round(2))
        st.write("recall_score:",recall_score(y_test,y_pred,labels=class_name).round(2))
        if 'confusion matrix' in metrics:
            st.subheader('confusion matrix')
            plot_confusion_matrix(svcclassifier,X_tested,y_test,display_labels=class_name)
            st.pyplot()
        if 'roc_curve' in metrics:
            st.subheader('plot_roc_curve')
            plot_roc_curve(svcclassifier,X_tested,y_test)
            st.pyplot()
        if 'precision_recall_curve' in metrics:
            st.subheader('precision_recall_curve')
            plot_roc_curve(svcclassifier,X_tested,y_test)
            st.pyplot()
        


if classifier_name == 'Logistic Regression':
    st.sidebar.subheader('Model Hyperparmeter')
    c= st.sidebar.number_input("c(Reguralization)",0.01,10.0,step=0.01,key='Logistic')
    max_iter= st.sidebar.slider("maximum number of iteration",100,500,key='max_item')
   

    metrics= st.sidebar.multiselect("What is the metrics to plot?",('confusion matrix','roc_curve','precision_recall_curve'))

    if st.sidebar.button("classify",key='classify'):
        st.subheader("Logistic Regression result")
        Regression= LogisticRegression(C=c,max_iter=max_iter)
        Regression.fit(X_trained,y_train)
        y_prediction= Regression.predict(X_tested)
        acc= accuracy_score(y_test,y_prediction)
        st.write("Accuracy:",acc.round(2))
        st.write("precision_score:",precision_score(y_test,y_prediction,labels=class_name).round(2))
        st.write("recall_score:",recall_score(y_test,y_prediction,labels=class_name).round(2))
        if 'confusion matrix' in metrics:
            st.subheader('confusion matrix')
            plot_confusion_matrix(Regression,X_tested,y_test,display_labels=class_name)
            st.pyplot()
        if 'roc_curve' in metrics:
            st.subheader('plot_roc_curve')
            plot_roc_curve(Regression,X_tested,y_test)
            st.pyplot()
        if 'precision_recall_curve' in metrics:
            st.subheader('precision_recall_curve')
            plot_roc_curve(Regression,X_tested,y_test)
            st.pyplot()
        
            

if classifier_name == 'Random Forest':
    st.sidebar.subheader('Model Hyperparmeter')
    n_estimators= st.sidebar.number_input("Number of trees in the forest",100,5000,step=10,key='estimators')
    max_depth= st.sidebar.number_input("maximum depth of tree",1,20,step=1,key='max_depth')
    bootstrap= st.sidebar.radio("Boostrap sample when building trees",("True","False"),key='boostrap')


    metrics= st.sidebar.multiselect("What is the metrics to plot?",('confusion matrix','roc_curve','precision_recall_curve'))

    if st.sidebar.button("classify",key='classify'):
        st.subheader("Random Forest result")
        model= RandomForestClassifier(n_estimators=n_estimators,max_depth=max_depth,bootstrap=bootstrap)
        model.fit(X_trained,y_train)
        y_prediction= model.predict(X_tested)
        acc= accuracy_score(y_test,y_prediction)
        st.write("Accuracy:",acc.round(2))
        st.write("precision_score:",precision_score(y_test,y_prediction,labels=class_name).round(2))
        st.write("recall_score:",recall_score(y_test,y_prediction,labels=class_name).round(2))
        if 'confusion matrix' in metrics:
            st.subheader('confusion matrix')
            plot_confusion_matrix(model,X_tested,y_test,display_labels=class_name)
            st.pyplot()
        if 'roc_curve' in metrics:
            st.subheader('plot_roc_curve')
            plot_roc_curve(model,X_tested,y_test)
            st.pyplot()
        if 'precision_recall_curve' in metrics:
            st.subheader('precision_recall_curve')
            plot_roc_curve(model,X_tested,y_test)
            st.pyplot() 


if classifier_name == 'KNN':
    st.sidebar.subheader('Model Hyperparmeter')
    n_neighbors= st.sidebar.number_input("Number of n_neighbors",5,30,step=1,key='neighbors')
    leaf_size= st.sidebar.slider("leaf size",30,200,key='leaf')
    weights= st.sidebar.radio("weight function used in prediction",("uniform","distance"),key='weight')


    metrics= st.sidebar.multiselect("What is the metrics to plot?",('confusion matrix','roc_curve','precision_recall_curve'))

    if st.sidebar.button("classify",key='classify'):
        st.subheader("KNN result")
        model= KNeighborsClassifier(n_neighbors=n_neighbors,leaf_size=leaf_size,weights=weights)
        model.fit(X_trained,y_train)
        y_prediction= model.predict(X_tested)
        acc= accuracy_score(y_test,y_prediction)
        st.write("Accuracy:",acc.round(2))
        st.write("precision_score:",precision_score(y_test,y_prediction,labels=class_name).round(2))
        st.write("recall_score:",recall_score(y_test,y_prediction,labels=class_name).round(2))
        if 'confusion matrix' in metrics:
            st.subheader('confusion matrix')
            plot_confusion_matrix(model,X_tested,y_test,display_labels=class_name)
            st.pyplot()
        if 'roc_curve' in metrics:
            st.subheader('plot_roc_curve')
            plot_roc_curve(model,X_tested,y_test)
            st.pyplot()
        if 'precision_recall_curve' in metrics:
            st.subheader('precision_recall_curve')
            plot_roc_curve(model,X_tested,y_test)
            st.pyplot() 


if classifier_name == 'XGBOOST':
    st.sidebar.subheader('Model Hyperparmeter')
    n_estimators= st.sidebar.number_input("Number of trees in the forest",100,5000,step=10,key='XGBestimators')
    seed= st.sidebar.number_input("number of the seed",1,150,step=1,key='seed')
    
    
    


    metrics= st.sidebar.multiselect("What is the metrics to plot?",('confusion matrix','roc_curve','precision_recall_curve'))

    if st.sidebar.button("classify",key='classify'):
        st.subheader("XGBOOST result")
        model= xgb.XGBClassifier(n_estimators=n_estimators,seed=seed)
        model.fit(X_trained,y_train)
        y_prediction= model.predict(X_tested)
        acc= accuracy_score(y_test,y_prediction)
        st.write("Accuracy:",acc.round(2))
        st.write("precision_score:",precision_score(y_test,y_prediction,labels=class_name).round(2))
        st.write("recall_score:",recall_score(y_test,y_prediction,labels=class_name).round(2))
        st.write("ROC_AUC_score:",roc_auc_score(y_test,y_prediction).round(2))

       

        if 'confusion matrix' in metrics:
            st.subheader('confusion matrix')
            plot_confusion_matrix(model,X_tested,y_test,display_labels=class_name)
            st.pyplot()
        if 'roc_curve' in metrics:
            st.subheader('plot_roc_curve')
            plot_roc_curve(model,X_tested,y_test)
            st.pyplot()
        if 'precision_recall_curve' in metrics:
            st.subheader('precision_recall_curve')
            plot_roc_curve(model,X_tested,y_test)
            st.pyplot() 

if st.sidebar.checkbox("Do u want to predict?",key='prediction'):

    st.sidebar.subheader('Model Prediction')
    gender= st.sidebar.number_input("what is your gender?",1,3,step=1,key='gender')
    security= st.sidebar.number_input("do u have online security?",1,3,step=1,key='security')
    techsupport= st.sidebar.number_input("do u have Techsupport",1,3,step=1,key='support')
    PaymentMethod= st.sidebar.number_input("do u have PaymentMethod",1,3,step=1,key='payment')

    if st.sidebar.button("Prediction",key='predict'):
        X_predict=[[gender,security,techsupport,PaymentMethod]]
        model= xgb.XGBClassifier(n_estimators=30,seed=14)
        model.fit(X_trained,y_train)
        y_user_prediction= model.predict(X_predict)
        if y_user_prediction==0:
          st.write("a new customer can result in a churn")
        else:
          st.write("a new customer can not result in a churn")





                  
